{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc356c4-a70d-45b6-91e9-bf9723290173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fraud Model Training Pipeline...\n",
      "Performing global feature engineering...\n",
      "\n",
      "==================================================\n",
      "Training model for: PROPERTY\n",
      "==================================================\n",
      "Training property model with 15 features on 1947 samples...\n",
      "\n",
      "--- PROPERTY Model Performance ---\n",
      "Test ROC-AUC: 0.7416\n",
      "Test F1-Score: 0.2745\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.86       387\n",
      "           1       0.40      0.21      0.27       100\n",
      "\n",
      "    accuracy                           0.77       487\n",
      "   macro avg       0.61      0.56      0.57       487\n",
      "weighted avg       0.73      0.77      0.74       487\n",
      "\n",
      "Confusion Matrix:\n",
      "[[355  32]\n",
      " [ 79  21]]\n",
      "✓ Saved pipeline to property_fraud_pipeline.joblib\n",
      "\n",
      "==================================================\n",
      "Training model for: LIFE\n",
      "==================================================\n",
      "Training life model with 15 features on 1924 samples...\n",
      "\n",
      "--- LIFE Model Performance ---\n",
      "Test ROC-AUC: 0.8662\n",
      "Test F1-Score: 0.6390\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       337\n",
      "           1       0.79      0.53      0.64       144\n",
      "\n",
      "    accuracy                           0.82       481\n",
      "   macro avg       0.81      0.74      0.76       481\n",
      "weighted avg       0.82      0.82      0.81       481\n",
      "\n",
      "Confusion Matrix:\n",
      "[[317  20]\n",
      " [ 67  77]]\n",
      "✓ Saved pipeline to life_fraud_pipeline.joblib\n",
      "\n",
      "==================================================\n",
      "Training model for: AUTOMOBILE\n",
      "==================================================\n",
      "Training automobile model with 18 features on 1998 samples...\n",
      "\n",
      "--- AUTOMOBILE Model Performance ---\n",
      "Test ROC-AUC: 0.9870\n",
      "Test F1-Score: 0.9856\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       186\n",
      "           1       0.99      0.98      0.99       314\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.98      0.98      0.98       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[184   2]\n",
      " [  7 307]]\n",
      "✓ Saved pipeline to automobile_fraud_pipeline.joblib\n",
      "\n",
      "==================================================\n",
      "Training model for: CROP\n",
      "==================================================\n",
      "Training crop model with 16 features on 1956 samples...\n",
      "\n",
      "--- CROP Model Performance ---\n",
      "Test ROC-AUC: 0.7192\n",
      "Test F1-Score: 0.2394\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       396\n",
      "           1       0.35      0.18      0.24        94\n",
      "\n",
      "    accuracy                           0.78       490\n",
      "   macro avg       0.59      0.55      0.56       490\n",
      "weighted avg       0.74      0.78      0.75       490\n",
      "\n",
      "Confusion Matrix:\n",
      "[[365  31]\n",
      " [ 77  17]]\n",
      "✓ Saved pipeline to crop_fraud_pipeline.joblib\n",
      "\n",
      "==================================================\n",
      "Training model for: PERSONAL_ACCIDENT\n",
      "==================================================\n",
      "Training personal_accident model with 14 features on 1904 samples...\n",
      "\n",
      "--- PERSONAL_ACCIDENT Model Performance ---\n",
      "Test ROC-AUC: 0.7555\n",
      "Test F1-Score: 0.2993\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87       388\n",
      "           1       0.38      0.25      0.30        89\n",
      "\n",
      "    accuracy                           0.78       477\n",
      "   macro avg       0.61      0.58      0.59       477\n",
      "weighted avg       0.75      0.78      0.77       477\n",
      "\n",
      "Confusion Matrix:\n",
      "[[352  36]\n",
      " [ 67  22]]\n",
      "✓ Saved pipeline to personal_accident_fraud_pipeline.joblib\n",
      "\n",
      "==================================================\n",
      "Training model for: TRAVEL\n",
      "==================================================\n",
      "Training travel model with 14 features on 1914 samples...\n",
      "\n",
      "--- TRAVEL Model Performance ---\n",
      "Test ROC-AUC: 0.7565\n",
      "Test F1-Score: 0.3108\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87       389\n",
      "           1       0.40      0.26      0.31        90\n",
      "\n",
      "    accuracy                           0.79       479\n",
      "   macro avg       0.62      0.58      0.59       479\n",
      "weighted avg       0.76      0.79      0.77       479\n",
      "\n",
      "Confusion Matrix:\n",
      "[[354  35]\n",
      " [ 67  23]]\n",
      "✓ Saved pipeline to travel_fraud_pipeline.joblib\n",
      "\n",
      "==================================================\n",
      "Training model for: HEALTH\n",
      "==================================================\n",
      "Training health model with 16 features on 1954 samples...\n",
      "\n",
      "--- HEALTH Model Performance ---\n",
      "Test ROC-AUC: 0.9042\n",
      "Test F1-Score: 0.7791\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       297\n",
      "           1       0.88      0.70      0.78       192\n",
      "\n",
      "    accuracy                           0.84       489\n",
      "   macro avg       0.85      0.82      0.83       489\n",
      "weighted avg       0.85      0.84      0.84       489\n",
      "\n",
      "Confusion Matrix:\n",
      "[[279  18]\n",
      " [ 58 134]]\n",
      "✓ Saved pipeline to health_fraud_pipeline.joblib\n",
      "\n",
      "==================================================\n",
      "TRAINING COMPLETE\n",
      "==================================================\n",
      "All model pipelines have been trained and saved.\n",
      "\n",
      "Model Performance Summary:\n",
      "property             | ROC-AUC: 0.7416 | F1: 0.2745\n",
      "life                 | ROC-AUC: 0.8662 | F1: 0.6390\n",
      "automobile           | ROC-AUC: 0.9870 | F1: 0.9856\n",
      "crop                 | ROC-AUC: 0.7192 | F1: 0.2394\n",
      "personal_accident    | ROC-AUC: 0.7555 | F1: 0.2993\n",
      "travel               | ROC-AUC: 0.7565 | F1: 0.3108\n",
      "health               | ROC-AUC: 0.9042 | F1: 0.7791\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline  # Pipeline that can include SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Starting Fraud Model Training Pipeline...\")\n",
    "\n",
    "# 1. Load Data\n",
    "try:\n",
    "    df = pd.read_csv('indian_multi_insurance_fraud_dataset.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: indian_multi_insurance_fraud_dataset.csv not found.\")\n",
    "    # Exit or raise error\n",
    "    exit()\n",
    "\n",
    "# 2. Global Feature Engineering (Applying logic from your notebook)\n",
    "print(\"Performing global feature engineering...\")\n",
    "date_columns = ['policy_start_date', 'claim_filing_date', 'incident_date']\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "df['policy_duration_days'] = (df['claim_filing_date'] - df['policy_start_date']).dt.days\n",
    "df['incident_to_claim_days'] = (df['claim_filing_date'] - df['incident_date']).dt.days\n",
    "\n",
    "# Handle potential NaT issues (if dates were invalid)\n",
    "df['policy_duration_days'].fillna(df['policy_duration_days'].median(), inplace=True)\n",
    "df['incident_to_claim_days'].fillna(df['incident_to_claim_days'].median(), inplace=True)\n",
    "\n",
    "\n",
    "# 3. Define Feature Lists (Based on your notebook analysis)\n",
    "# NOTE: We are intentionally DROPPING high-cardinality text fields \n",
    "# (accident_location, treatment_details) for V1, as they require complex NLP processing.\n",
    "# Your notebook also struggled with these in the XAI phase.\n",
    "\n",
    "TARGET = 'fraud_reported'\n",
    "\n",
    "# Common features available for ALL types\n",
    "common_features = [\n",
    "    'insured_age', 'insured_sex', 'insured_occupation', 'policy_state',\n",
    "    'policy_annual_premium', 'claim_amount', 'sum_insured',\n",
    "    'claim_amount_to_sum_insured_ratio', 'previous_claims_count',\n",
    "    'policy_renewal_status', 'premium_payment_delays',\n",
    "    'coverage_changes_before_claim', 'policy_duration_days', 'incident_to_claim_days'\n",
    "]\n",
    "\n",
    "# Insurance-specific features (only features that are NOT high-cardinality text)\n",
    "insurance_specific_features = {\n",
    "    'health': ['claim_duration_days', 'hospital_name'], # Dropped treatment_details\n",
    "    'life': ['nominee_relationship'],\n",
    "    'automobile': ['auto_make', 'auto_model', 'auto_year', 'third_party_involved'], # Dropped accident_location\n",
    "    'property': ['property_type'],\n",
    "    'crop': ['crop_type', 'weather_condition'],\n",
    "    'travel': [],\n",
    "    'personal_accident': []\n",
    "}\n",
    "\n",
    "# Define data types for preprocessing\n",
    "CATEGORICAL_COMMON = ['insured_sex', 'insured_occupation', 'policy_state',\n",
    "                     'policy_renewal_status', 'premium_payment_delays',\n",
    "                     'coverage_changes_before_claim']\n",
    "                     \n",
    "NUMERIC_COMMON = ['insured_age', 'policy_annual_premium', 'claim_amount', 'sum_insured',\n",
    "                 'claim_amount_to_sum_insured_ratio', 'previous_claims_count',\n",
    "                 'policy_duration_days', 'incident_to_claim_days']\n",
    "\n",
    "CATEGORICAL_SPECIFIC = {\n",
    "    'health': ['hospital_name'],\n",
    "    'life': ['nominee_relationship'],\n",
    "    'automobile': ['auto_make', 'auto_model', 'third_party_involved'],\n",
    "    'property': ['property_type'],\n",
    "    'crop': ['crop_type', 'weather_condition'],\n",
    "    'travel': [],\n",
    "    'personal_accident': []\n",
    "}\n",
    "\n",
    "NUMERIC_SPECIFIC = {\n",
    "    'health': ['claim_duration_days'],\n",
    "    'life': [],\n",
    "    'automobile': ['auto_year'],\n",
    "    'property': [],\n",
    "    'crop': [],\n",
    "    'travel': [],\n",
    "    'personal_accident': []\n",
    "}\n",
    "\n",
    "# 4. Model Training Loop\n",
    "# We will create and save 7 specialized pipelines.\n",
    "\n",
    "artifacts = {}\n",
    "model_performance = {}\n",
    "\n",
    "for insurance_type in df['insurance_type'].unique():\n",
    "    print(f\"\\n{'='*50}\\nTraining model for: {insurance_type.upper()}\\n{'='*50}\")\n",
    "\n",
    "    # 1. Filter data for the specific insurance type\n",
    "    type_df = df[df['insurance_type'] == insurance_type].copy()\n",
    "\n",
    "    # 2. Define features for this specific model\n",
    "    specific_cats = CATEGORICAL_SPECIFIC.get(insurance_type, [])\n",
    "    specific_nums = NUMERIC_SPECIFIC.get(insurance_type, [])\n",
    "    \n",
    "    all_numeric_features = NUMERIC_COMMON + specific_nums\n",
    "    all_categorical_features = CATEGORICAL_COMMON + specific_cats\n",
    "    \n",
    "    all_features = all_numeric_features + all_categorical_features\n",
    "    \n",
    "    X = type_df[all_features]\n",
    "    y = type_df[TARGET]\n",
    "\n",
    "    # 3. Create Preprocessing Pipelines\n",
    "    # Pipeline for numerical features: impute missing values (if any) with the median, then scale.\n",
    "    numeric_pipeline = ImbPipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Pipeline for categorical features: impute missing (if any) with the most frequent value, then one-hot encode.\n",
    "    # handle_unknown='ignore' is crucial so the model doesn't break if it sees a new value in production.\n",
    "    categorical_pipeline = ImbPipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    # 4. Create the main Preprocessor using ColumnTransformer\n",
    "    # This applies the correct pipeline to the correct columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_pipeline, all_numeric_features),\n",
    "            ('cat', categorical_pipeline, all_categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough' # Pass through any columns we missed (should be none)\n",
    "    )\n",
    "\n",
    "    # 5. Create the Full ML Pipeline (Preprocessing + SMOTE + Model)\n",
    "    # Using ImbPipeline allows SMOTE (for imbalance) to work correctly *within* the pipeline.\n",
    "    full_pipeline = ImbPipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('model', RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "    # 6. Split data and Train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    print(f\"Training {insurance_type} model with {len(all_features)} features on {len(X_train)} samples...\")\n",
    "    full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # 7. Evaluate\n",
    "    y_pred = full_pipeline.predict(X_test)\n",
    "    y_proba = full_pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n--- {insurance_type.upper()} Model Performance ---\")\n",
    "    print(f\"Test ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Test F1-Score: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # 8. Save the entire pipeline object (model + preprocessors)\n",
    "    artifact_filename = f\"{insurance_type}_fraud_pipeline.joblib\"\n",
    "    joblib.dump(full_pipeline, artifact_filename)\n",
    "    print(f\"✓ Saved pipeline to {artifact_filename}\")\n",
    "    \n",
    "    # Store results\n",
    "    artifacts[insurance_type] = artifact_filename\n",
    "    model_performance[insurance_type] = {'roc_auc': roc_auc, 'f1_score': f1, 'features_used': all_features}\n",
    "\n",
    "\n",
    "print(f\"\\n{'='*50}\\nTRAINING COMPLETE\\n{'='*50}\")\n",
    "print(\"All model pipelines have been trained and saved.\")\n",
    "\n",
    "# Display summary:\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "for insurance_type, perf in model_performance.items():\n",
    "    print(f\"{insurance_type:<20} | ROC-AUC: {perf['roc_auc']:.4f} | F1: {perf['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea663b6-20de-4aa3-9b6c-3370a5023f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
